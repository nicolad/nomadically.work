# src/promptfoo/remote-jobs.promptfooconfig.yaml
description: "Remote AI jobs pipeline evals (2 buckets, strict remote/region/freshness, dedupe) via Promptfoo + Cloudflare"

prompts:
  # Langfuse-managed prompt (production label)
  # Update prompts in Langfuse UI without changing this config
  - "langfuse://remote-ai-jobs-eval@production"

providers:
  # Cloudflare Worker provider - routes extraction through the edge-deployed
  # promptfoo-eval worker (workers/promptfoo-eval.ts). Requires PROMPTFOO_WORKER_URL.
  # Uses native Workers AI binding on the edge â€” no API key needed at runtime.
  # Uncomment to enable:
  # - id: file://./providers/cloudflare-worker-provider.ts
  #   label: cf-worker-llama-3.3-70b

# Default assertions for all tests
defaultTest:
  assert:
    # 1) Must parse as JSON and satisfy schema
    - type: is-json
      schema: file://./schemas/remoteJobsOutput.schema.json

    # 2) Exactly two buckets: worldwide + europe
    - type: javascript
      value: file://./assertions/twoBucketsOnly.js

    # 3) Strict invariants: remote/region/freshness/dedupe
    - type: javascript
      value: file://./assertions/strictInvariants.js

    # 4) Fixture regression: ensure known bad URLs are excluded (fixture-only tests)
    - type: javascript
      value: file://./assertions/excludesBadUrls.js

    # 5) No job aggregator listing pages (must be direct job postings)
    - type: javascript
      value: file://./assertions/noAggregatorListingPages.js

tests:
  # ----------------------------
  # Live test with Cloudflare Workers AI (DeepSeek R1 32B at the edge)
  # Requires CLOUDFLARE_ACCOUNT_ID + CLOUDFLARE_API_KEY
  # Change cf_model to any model from CLOUDFLARE_AI_MODELS in src/promptfoo/constants.ts
  # ----------------------------
  # - description: "Live: Cloudflare Workers AI (DeepSeek-R1-32B), last-7d worldwide+europe"
  #   vars:
  #     mode: "live"
  #     queryHint: "agentic"
  #     maxCandidatesPerMode: 25
  #     verifyTopNWithContext: 8
  #     minConfidence: 0.6
  #     max_hours_ago: 168
  #     llm_provider: "cloudflare"
  #     cf_model: "@cf/deepseek-ai/deepseek-r1-distill-qwen-32b"

  # ----------------------------
  # Live test via deployed Cloudflare Worker (uses native Workers AI binding at edge)
  # Requires PROMPTFOO_WORKER_URL (set after pnpm deploy:promptfoo)
  # Provider: file://./providers/cloudflare-worker-provider.ts
  # ----------------------------
  # - description: "Live: Cloudflare Worker (Llama-3.3-70B native binding), last-7d"
  #   vars:
  #     mode: "live"
  #     queryHint: "agentic"
  #     maxCandidatesPerMode: 25
  #     verifyTopNWithContext: 8
  #     minConfidence: 0.6
  #     max_hours_ago: 168
  #     cf_model: "@cf/meta/llama-3.3-70b-instruct-fp8-fast"
